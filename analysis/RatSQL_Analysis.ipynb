{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","from google.colab import files\n","drive.mount('/content/gdrive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wijJOIyRRAFN","executionInfo":{"status":"ok","timestamp":1735262413589,"user_tz":300,"elapsed":3213,"user":{"displayName":"","userId":""}},"outputId":"0ce52f58-3724-4c5d-cb98-064ce9fceb0f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/RAT_SQL_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsnmfOA6SSWL","executionInfo":{"status":"ok","timestamp":1735262416882,"user_tz":300,"elapsed":146,"user":{"displayName":"","userId":""}},"outputId":"51baf22b-b201-448a-c9da-7edccb7d0698"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/RAT_SQL_Project\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"USdt2qXlSu_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tyxrLYPI3Ry","outputId":"5a824900-a531-47a5-d36d-8a70dced7c9c","executionInfo":{"status":"ok","timestamp":1735258474014,"user_tz":300,"elapsed":2255,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'rat-sql'...\n","remote: Enumerating objects: 161, done.\u001b[K\n","remote: Counting objects: 100% (92/92), done.\u001b[K\n","remote: Compressing objects: 100% (52/52), done.\u001b[K\n","remote: Total 161 (delta 47), reused 40 (delta 40), pack-reused 69 (from 1)\u001b[K\n","Receiving objects: 100% (161/161), 113.94 KiB | 833.00 KiB/s, done.\n","Resolving deltas: 100% (54/54), done.\n"]}],"source":["#COmment this line after cloning the RAT-SQL model\n","#!git clone https://github.com/microsoft/rat-sql"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"SuBdZ071JJCB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735258498221,"user_tz":300,"elapsed":3044,"user":{"displayName":"","userId":""}},"outputId":"3195170c-8719-41f4-9023-56d7b98d99dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"]}],"source":["!python3 -m pip install torch torchvision"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4COFR5pnJP6I","outputId":"86d3ebcf-69e9-4fe9-b33a-49d52af687e2","executionInfo":{"status":"ok","timestamp":1735258525363,"user_tz":300,"elapsed":1848,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/parse_url.py:48: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/file/d/1403EGqzIDoHMdQF4c9Bkyl7dZLZ5Wt6J\n","To: /content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/1403EGqzIDoHMdQF4c9Bkyl7dZLZ5Wt6J\n","91.9kB [00:00, 9.73MB/s]\n","tar: spider.tar.gz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n"]}],"source":["import os\n","#Copy spider dataset into gdrive\n","os.chdir(\"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql\")\n","!mkdir -p third_party/stanford-corenlp-full-2018-10-05\n","!gdown https://drive.google.com/file/d/1403EGqzIDoHMdQF4c9Bkyl7dZLZ5Wt6J\n","!mkdir data\n","!tar -xvf spider.tar.gz -C data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DuitSYEDJ6E0","outputId":"20589bff-41a4-463a-890b-18e65d3d6e99","executionInfo":{"status":"ok","timestamp":1735259006603,"user_tz":300,"elapsed":102653,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jsonnet\n","  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/594.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/594.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torchtext\n","  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n","Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (2.16.0)\n","Collecting records\n","  Downloading records-0.6.0-py2.py3-none-any.whl.metadata (7.7 kB)\n","Collecting asdl\n","  Downloading asdl-0.1.5.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting astor\n","  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (24.3.0)\n","Collecting bpemb\n","  Downloading bpemb-0.3.6-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n","Collecting pyrsistent\n","  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Collecting stanford-corenlp\n","  Downloading stanford_corenlp-3.9.2-py2.py3-none-any.whl.metadata (9.1 kB)\n","Collecting entmax\n","  Downloading entmax-1.3-py3-none-any.whl.metadata (348 bytes)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n","Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: SQLAlchemy>=2.0 in /usr/local/lib/python3.10/dist-packages (from records) (2.0.36)\n","Collecting tablib>=0.11.4 (from records)\n","  Downloading tablib-3.7.0-py3-none-any.whl.metadata (3.8 kB)\n","Requirement already satisfied: openpyxl>2.6.0 in /usr/local/lib/python3.10/dist-packages (from records) (3.1.5)\n","Collecting docopt (from records)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb) (0.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Collecting corenlp-protobuf>=3.8.0 (from stanford-corenlp)\n","  Downloading corenlp_protobuf-3.8.0-py2.py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from stanford-corenlp) (1.17.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from corenlp-protobuf>=3.8.0->stanford-corenlp) (4.25.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>2.6.0->records) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.12.14)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=2.0->records) (3.1.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (7.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->bpemb) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n","Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading records-0.6.0-py2.py3-none-any.whl (10.0 kB)\n","Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Downloading bpemb-0.3.6-py3-none-any.whl (20 kB)\n","Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading stanford_corenlp-3.9.2-py2.py3-none-any.whl (11 kB)\n","Downloading entmax-1.3-py3-none-any.whl (13 kB)\n","Downloading corenlp_protobuf-3.8.0-py2.py3-none-any.whl (15 kB)\n","Downloading tablib-3.7.0-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: jsonnet, asdl, docopt\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp310-cp310-linux_x86_64.whl size=6406869 sha256=829e03f4c8ddf4b006201540332a45cf4d39c518cf990b487687759a52b5bd5c\n","  Stored in directory: /root/.cache/pip/wheels/63/0d/6b/5467dd1db9332ba4bd5cf4153e2870c5f89bb4db473d989cc2\n","  Building wheel for asdl (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for asdl: filename=asdl-0.1.5-py3-none-any.whl size=9902 sha256=3aa4f518513223b4b2b034e31523a5703fb1a3ac8b759e838e0063c454576529\n","  Stored in directory: /root/.cache/pip/wheels/7c/7a/2e/e50b21d4eea8b81b075a77d52c07483ba81e7f2ce90f1e0c81\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d038c025e900f3575e171fefe0331fc086b381b9d0ac4fd130e0f371509829c9\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built jsonnet asdl docopt\n","Installing collected packages: jsonnet, docopt, asdl, tablib, pyrsistent, corenlp-protobuf, astor, stanford-corenlp, records, torchtext, entmax, bpemb\n","Successfully installed asdl-0.1.5 astor-0.8.1 bpemb-0.3.6 corenlp-protobuf-3.8.0 docopt-0.6.2 entmax-1.3 jsonnet-0.20.0 pyrsistent-0.20.0 records-0.6.0 stanford-corenlp-3.9.2 tablib-3.7.0 torchtext-0.18.0\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["!python3 -m pip install jsonnet torchtext transformers babel records asdl astor attrs bpemb networkx pyrsistent nltk stanford-corenlp entmax\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHBMe0-NL6GB","outputId":"bb586966-efe1-4780-a40f-07fd4419aef3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"XEi7MVh2GKht"},"source":["Copy the glove 42B version in the .vector folder"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogbEFbpsMIes","outputId":"8718295d-7f76-4722-8467-392693acb7cb","executionInfo":{"status":"ok","timestamp":1735259184196,"user_tz":300,"elapsed":331,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘.vector_cache/’: File exists\n"]}],"source":["import os\n","!mkdir .vector_cache/\n","#!cp -r /content/drive/MyDrive/glove-42B/glove.42B.300d.zip /content/rat-sql/.vector_cache/\n","os.chdir('/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/.vector_cache')\n","#!unzip glove.42B.300d.zip\n"]},{"cell_type":"markdown","metadata":{"id":"00LuK1hbGU4l"},"source":["Copy the latest stanford nlp. Version 4.5.7 has been used for this study"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zK5wWWJlLNEd","outputId":"8b1bce83-548c-4141-a00f-e18f9513ece9","executionInfo":{"status":"ok","timestamp":1735260341529,"user_tz":300,"elapsed":270,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open stanford-corenlp-4.5.7.zip, stanford-corenlp-4.5.7.zip.zip or stanford-corenlp-4.5.7.zip.ZIP.\n","mv: cannot stat 'stanford-corenlp-4.5.7': No such file or directory\n"]}],"source":["import os\n","os.chdir('/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/third_party')\n","#!cp /content/drive/MyDrive/stanford-corenlp-4.5.5.zip ./\n","!unzip stanford-corenlp-4.5.7.zip\n","!mv stanford-corenlp-4.5.7 stanford-corenlp-full/\n","# !cp -r /content/drive/MyDrive/stanford-corenlp-4.5.5 /content/rat-sql/third_party/stanford-corenlp-full-2018-10-05\n","# !cp -r /content/drive/MyDrive/nl2code-glove,cv_link=true /content/rat-sql/data/spider"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCVZN1ZdLqix","outputId":"1c1ed1c9-8915-46c0-c212-df25028480ff","executionInfo":{"status":"ok","timestamp":1735262529153,"user_tz":300,"elapsed":388,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["declare -x CORENLP_HOME=\"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/third_party/stanford-corenlp-full/stanford-corenlp-4.5.7\"\n","/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/third_party/stanford-corenlp-full/stanford-corenlp-4.5.7\n"]}],"source":["import os\n","os.environ['CORENLP_HOME'] = \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/third_party/stanford-corenlp-full/stanford-corenlp-4.5.7\"\n","!export | grep CORENLP_HOME\n","!declare -x CORENLP_HOME=\"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/third_party/stanford-corenlp-full/stanford-corenlp-4.5.7\"\n","!echo $CORENLP_HOME"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6xxMlW0PLvCD","executionInfo":{"status":"ok","timestamp":1735262513514,"user_tz":300,"elapsed":145,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["import os\n","os.chdir('/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ZQ8eN5alGkbl","executionInfo":{"status":"ok","timestamp":1735262797926,"user_tz":300,"elapsed":979,"user":{"displayName":"","userId":""}},"outputId":"c936117a-e758-4640-cac2-ae29f3c191de","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/run.py\", line 8, in <module>\n","    from ratsql.commands import preprocess, train, infer, eval\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/commands/preprocess.py\", line 11, in <module>\n","    from ratsql import grammars\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/grammars/__init__.py\", line 2, in <module>\n","    from . import wikisql\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/grammars/wikisql.py\", line 12, in <module>\n","    from ratsql.resources import corenlp\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/resources/__init__.py\", line 1, in <module>\n","    from . import pretrained_embeddings\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/resources/pretrained_embeddings.py\", line 7, in <module>\n","    import corenlp\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp/__init__.py\", line 1, in <module>\n","    from corenlp_protobuf import to_text\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp_protobuf/__init__.py\", line 7, in <module>\n","    from .CoreNLP_pb2 import *\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp_protobuf/CoreNLP_pb2.py\", line 32, in <module>\n","    _descriptor.EnumValueDescriptor(\n","  File \"/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py\", line 789, in __new__\n","    _message.Message._CheckCalledFromGeneratedFile()\n","TypeError: Descriptors cannot be created directly.\n","If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n","If you cannot immediately regenerate your protos, some other possible workarounds are:\n"," 1. Downgrade the protobuf package to 3.20.x or lower.\n"," 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n","\n","More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"]}],"source":["!PYTHONPATH=/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ python3 run.py preprocess experiments/spider-glove-run.jsonnet"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLT1vR6_Lz6q","outputId":"ba5057af-61f0-4a8d-d4b2-31b1f37b2983","executionInfo":{"status":"ok","timestamp":1735262846281,"user_tz":300,"elapsed":5287,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/run.py\", line 8, in <module>\n","    from ratsql.commands import preprocess, train, infer, eval\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/commands/preprocess.py\", line 11, in <module>\n","    from ratsql import grammars\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/grammars/__init__.py\", line 2, in <module>\n","    from . import wikisql\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/grammars/wikisql.py\", line 12, in <module>\n","    from ratsql.resources import corenlp\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/resources/__init__.py\", line 1, in <module>\n","    from . import pretrained_embeddings\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/resources/pretrained_embeddings.py\", line 7, in <module>\n","    import corenlp\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp/__init__.py\", line 1, in <module>\n","    from corenlp_protobuf import to_text\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp_protobuf/__init__.py\", line 7, in <module>\n","    from .CoreNLP_pb2 import *\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp_protobuf/CoreNLP_pb2.py\", line 32, in <module>\n","    _descriptor.EnumValueDescriptor(\n","  File \"/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py\", line 789, in __new__\n","    _message.Message._CheckCalledFromGeneratedFile()\n","TypeError: Descriptors cannot be created directly.\n","If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n","If you cannot immediately regenerate your protos, some other possible workarounds are:\n"," 1. Downgrade the protobuf package to 3.20.x or lower.\n"," 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n","\n","More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"]}],"source":["!PYTHONPATH=/content/rat-sql/ python3 run.py train experiments/spider-glove-run.jsonnet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u2Zh4YOFVXwH"},"outputs":[],"source":["# !rm -rf /content/rat-sql/logdir\n","# !cp /content/rat-sql/logdir/bert_run/bs=4,lr=7.4e-04,bert_lr=3.0e-06,end_lr=0e0,att=1/model_checkpoint-00001000 /content/drive/MyDrive"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q45sSDaNL1Pi","outputId":"35637345-677a-42ab-ddf7-cf0bf622c3da","executionInfo":{"status":"ok","timestamp":1735262873185,"user_tz":300,"elapsed":4694,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/run.py\", line 8, in <module>\n","    from ratsql.commands import preprocess, train, infer, eval\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/commands/preprocess.py\", line 11, in <module>\n","    from ratsql import grammars\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/grammars/__init__.py\", line 2, in <module>\n","    from . import wikisql\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/grammars/wikisql.py\", line 12, in <module>\n","    from ratsql.resources import corenlp\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/resources/__init__.py\", line 1, in <module>\n","    from . import pretrained_embeddings\n","  File \"/content/gdrive/MyDrive/RAT_SQL_Project/rat-sql/ratsql/resources/pretrained_embeddings.py\", line 7, in <module>\n","    import corenlp\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp/__init__.py\", line 1, in <module>\n","    from corenlp_protobuf import to_text\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp_protobuf/__init__.py\", line 7, in <module>\n","    from .CoreNLP_pb2 import *\n","  File \"/usr/local/lib/python3.10/dist-packages/corenlp_protobuf/CoreNLP_pb2.py\", line 32, in <module>\n","    _descriptor.EnumValueDescriptor(\n","  File \"/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py\", line 789, in __new__\n","    _message.Message._CheckCalledFromGeneratedFile()\n","TypeError: Descriptors cannot be created directly.\n","If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n","If you cannot immediately regenerate your protos, some other possible workarounds are:\n"," 1. Downgrade the protobuf package to 3.20.x or lower.\n"," 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n","\n","More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"]}],"source":["!PYTHONPATH=/content/rat-sql/ python3 run.py eval experiments/spider-glove-run.jsonnet"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/shadabmazhari/RAT_SQL_Project/blob/main/RatSQL.ipynb","timestamp":1735263562356}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}